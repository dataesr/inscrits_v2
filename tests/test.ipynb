{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_import import *\n",
    "from config_path import PATH\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_source(source, rentree):\n",
    "    import pandas as pd, zipfile\n",
    "    from modules.sise_content import src_load\n",
    "\n",
    "    filename = f'{source}{str(rentree)[2:4]}'\n",
    "    print(filename)\n",
    "\n",
    "    from config_path import PATH\n",
    "    with zipfile.ZipFile(f\"{PATH}input/parquet_origine.zip\", 'r') as z:\n",
    "        df = pd.read_parquet(z.open(f'{filename}.parquet'), engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_individual_source('mana', '2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TYPREPA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global CONF\n",
    "CONF=json.load(open('utils/config_sise.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_RENTREES = list(range(2004, 2004+1))\n",
    "ALL_RENTREES = [2013]\n",
    "for rentree in ALL_RENTREES:\n",
    "    df_all = pd.DataFrame()\n",
    "    # sources = get_sources(rentree)\n",
    "    sources = ['mana']\n",
    "    for source in sources:\n",
    "\n",
    "        filename = f'{source}{str(rentree)[2:4]}'\n",
    "        print(filename)\n",
    "\n",
    "\n",
    "        # chargement des tables en conservant que les variables de la liste utils/vars_list\n",
    "        df = src_load(filename, source, rentree)\n",
    "\n",
    "        # to check the data from the new datasets\n",
    "        # with pd.ExcelWriter(excel_path, mode='a', if_sheet_exists=\"replace\") as writer:  \n",
    "        #     pd.DataFrame({\"name\": df.columns, \"non-nulls\": len(df)-df.isnull().sum().values, \"nulls\": df.isnull().sum().values}).to_excel(writer, sheet_name=filename, index=False)\n",
    "\n",
    "        # df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    # df_all = correctif_vars(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.typrepa.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.head(5)\n",
    "df_all.value_counts(['rentree', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.net.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "df_all.head(5)\n",
    "# df.voie.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[conf.get('var_sise') for conf in CONF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIFS_dict = get_all_correctifs()\n",
    "BCN = bcn_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vars_sise_to_be_check(year, bcn, com):\n",
    "    from config_path import PATH\n",
    "    # from utils.vars_in_nomen import vbcn\n",
    "    import pandas as pd, json\n",
    "\n",
    "    CONF=json.load(open('utils/config_sise.json', 'r'))\n",
    "    vars_sise = pd.read_pickle(f\"{PATH}output/items_by_vars{year}.pkl\", compression='gzip')\n",
    "\n",
    "    hors_nomen=pd.DataFrame()\n",
    "\n",
    "    for conf in CONF:\n",
    "        var_sise = conf[\"var_sise\"]\n",
    "        nomen = conf[\"n_data\"]\n",
    "\n",
    "        if nomen:\n",
    "            print(f\"#### {var_sise}\")\n",
    "            if var_sise in ['cometa', 'comins']:\n",
    "                l=pd.DataFrame.from_dict(com[nomen]).iloc[:,0].unique()\n",
    "            else:\n",
    "                if var_sise in bcn[nomen].columns:\n",
    "                    l=bcn[nomen][var_sise].unique()\n",
    "                else:\n",
    "                    print(f\"- le nom de variable {var_sise} n'existe pas dans {nomen}\\n - le code suivant va extraire la 1ere colonne {bcn[nomen].columns[0]}\")\n",
    "                    l=bcn[nomen].iloc[:,0].unique()\n",
    "                \n",
    "            tmp=vars_sise.loc[(vars_sise.variable==var_sise)].assign(nomenclature=nomen)\n",
    "            tmp.loc[~tmp.item.isin(l), 'hors_nomenclature'] = '1'\n",
    "            hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)  \n",
    "\n",
    "        # hors_nomen.to_csv(f\"{PATH}test/vars_hs_nomen.csv\", sep=';', encoding='utf-8', index=False, na_rep='', float_format='str')\n",
    "   \n",
    "    return hors_nomen\n",
    "vars_sise_to_be_check(2024, BCN, CORRECTIFS_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hors_nomen=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    if k in bcn[v].columns:\n",
    "        l=bcn[v][k].unique()\n",
    "        # tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "        # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"- le nom de variable {k} n'existe pas dans {v}\\nla 1ere colonne est {bcn[v].iloc[:,0]}, le code suivant va extraire la 1ere colonne\")\n",
    "        l=bcn[v].iloc[:,0].unique()\n",
    "        tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))]\n",
    "        hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)      \n",
    "\n",
    "hors_nomen=hors_nomen.pivot_table(index=['rentree', 'variable', 'item'], columns='source',   values='count', \n",
    "    aggfunc='sum').reset_index()\n",
    "hors_nomen.fillna('',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# work_csv(hors_nomen, 'modalites_hsn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    l=bcn[v].iloc[:,0].unique()\n",
    "    tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "    # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=T:rue)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in vbcn.items():\n",
    "#     bcn[v].columns=bcn[v].columns.str.lower()\n",
    "#     l=bcn[v].iloc[:,0].unique()\n",
    "#     print(f\"{v} -> {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bcn:\n",
    "    x=bcn[i]\n",
    "    print(f\"{i} -> {x.iloc[:,0].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn['N_SPECIALISATION'][bcn['N_SPECIALISATION'].specialisation=='0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_csv(bcn['N_PARCOURS_TYPE_SISE'], 'parcours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.read_csv(f\"{PATH}sise_config.csv\", encoding='utf-8', na_values=' ', keep_default_na=False, sep=';', dtype='str')\n",
    "t.to_json('utils/config_sise.json', orient='records', compression='infer', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import sise_config\n",
    "CONF=sise_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.load(open('utils/config_sise.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
