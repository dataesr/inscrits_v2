{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_import import *\n",
    "from config_path import PATH\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Retourner la série et la dernière année des données\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [parquet_files, last_data_year]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m dataset_list, last_data_year = \u001b[43mzip_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mzip_content\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     13\u001b[39m             parquet_files.append(file_name.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] )\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Extraire la dernière année des données en utilisant le dernier élément de la série\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     last_data_year = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m20\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mparquet_files\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m[-\u001b[32m1\u001b[39m][-\u001b[32m2\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Retourner la série et la dernière année des données\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [parquet_files, last_data_year]\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "def zip_content():\n",
    "    # Importer le chemin de configuration depuis un module externe\n",
    "    from config_path import PATH\n",
    "\n",
    "    # Ouvrir le fichier ZIP en mode lecture\n",
    "    parquet_files = []\n",
    "\n",
    "    with zipfile.ZipFile(f\"{PATH}input/parquet_origine.zip\", 'r') as zip_ref:\n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.endswith('.parquet'):\n",
    "                # Extraire uniquement le nom du fichier sans le chemin\n",
    "                file_name = os.path.basename(file_info.filename)\n",
    "                parquet_files.append(file_name.split('.')[0] )\n",
    "\n",
    "        # Extraire la dernière année des données en utilisant le dernier élément de la série\n",
    "        last_data_year = f'20{parquet_files.iloc[-1][-2:]}'\n",
    "\n",
    "    # Retourner la série et la dernière année des données\n",
    "    return [parquet_files, last_data_year]\n",
    "dataset_list, last_data_year = zip_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_source(source, rentree):\n",
    "    import pandas as pd, zipfile\n",
    "    from step1_data_init.sise_content import src_load\n",
    "\n",
    "    filename = f'{source}{str(rentree)[2:4]}'\n",
    "    print(filename)\n",
    "\n",
    "    from config_path import PATH\n",
    "    with zipfile.ZipFile(f\"{PATH}input/parquet_origine.zip\", 'r') as z:\n",
    "        df = pd.read_parquet(z.open(f'{filename}.parquet'), engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mana13\n"
     ]
    }
   ],
   "source": [
    "df=get_individual_source('mana', '2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '12202', '11205', '12201', '13201', '12203', '11101',\n",
       "       '13202', 'A', '11201', '12205', '11203', '1', '13101', '12206',\n",
       "       '11207', '12204', '13203', '11210', '12207', '12102', '11211',\n",
       "       '11206', '11209', '11213', '11202', 'D', '12101', '11103', '11109',\n",
       "       '2A EC', '2A  E', '1A LE', '1A EC', 'MP (M', '2A EN', '2A GR',\n",
       "       'PC (P', '1A EN', 'PC* (', 'MPSI', 'ENS C', '2A SA', '12103',\n",
       "       '13103', '12104', '11215', '12105', '?', '0', '11204', '11105',\n",
       "       '11212', '13205', '11110'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TYPREPA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global CONF\n",
    "CONF=json.load(open('utils/config_sise.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctif_vars(df):\n",
    "    for conf in CONF:\n",
    "        var_sise = conf[\"var_sise\"]\n",
    "        format_type = conf[\"format\"]\n",
    "        missing_value = conf[\"missing_value\"]\n",
    "\n",
    "        if var_sise in df.columns:\n",
    "            if format_type=='str':\n",
    "                df[var_sise] = df[var_sise].astype(format_type)\n",
    "                df[var_sise] = df[var_sise].str.split('.0', regex=False).str[0].str.strip()\n",
    "                df.loc[df[var_sise].str.contains(r'^(nan|none)$', regex=True, case=False), var_sise] = ''        \n",
    "                df = df.mask(df=='')\n",
    "                df[var_sise] = df[var_sise].fillna(missing_value)\n",
    "\n",
    "            if format_type=='int':\n",
    "                df[var_sise] = pd.to_numeric(df[var_sise], errors='coerce').astype('Int64')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def src_load(filename, source, rentree):\n",
    "    from config_path import PATH\n",
    "    from utils.constants import get_vars\n",
    "    with zipfile.ZipFile(f\"{PATH}input/parquet_origine.zip\", 'r') as z:\n",
    "        df = pd.read_parquet(z.open(f'parquet_origine/{filename}.parquet'), engine='pyarrow')\n",
    "\n",
    "    # list columns and lowercase name, create vars RENTREE/SOURCE\n",
    "    df_vars = df[df.columns[df.columns.str.lower().isin([conf.get('var_sise') for conf in CONF])]]\n",
    "    df_vars.columns = df_vars.columns.str.lower()\n",
    "    df_vars = df_vars.assign(rentree=rentree, source=source)\n",
    "    return df_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mana13\n"
     ]
    }
   ],
   "source": [
    "# ALL_RENTREES = list(range(2004, 2004+1))\n",
    "ALL_RENTREES = [2013]\n",
    "for rentree in ALL_RENTREES:\n",
    "    df_all = pd.DataFrame()\n",
    "    # sources = get_sources(rentree)\n",
    "    sources = ['mana']\n",
    "    for source in sources:\n",
    "\n",
    "        filename = f'{source}{str(rentree)[2:4]}'\n",
    "        print(filename)\n",
    "\n",
    "\n",
    "        # chargement des tables en conservant que les variables de la liste utils/vars_list\n",
    "        df = src_load(filename, source, rentree)\n",
    "\n",
    "        # to check the data from the new datasets\n",
    "        # with pd.ExcelWriter(excel_path, mode='a', if_sheet_exists=\"replace\") as writer:  \n",
    "        #     pd.DataFrame({\"name\": df.columns, \"non-nulls\": len(df)-df.isnull().sum().values, \"nulls\": df.isnull().sum().values}).to_excel(writer, sheet_name=filename, index=False)\n",
    "\n",
    "        # df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    # df_all = correctif_vars(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '12202', '11205', '12201', '13201', '12203', '11101',\n",
       "       '13202', 'A', '11201', '12205', '11203', '1', '13101', '12206',\n",
       "       '11207', '12204', '13203', '11210', '12207', '12102', '11211',\n",
       "       '11206', '11209', '11213', '11202', 'D', '12101', '11103', '11109',\n",
       "       '2A EC', '2A  E', '1A LE', '1A EC', 'MP (M', '2A EN', '2A GR',\n",
       "       'PC (P', '1A EN', 'PC* (', 'MPSI', 'ENS C', '2A SA', '12103',\n",
       "       '13103', '12104', '11215', '12105', '?', '0', '11204', '11105',\n",
       "       '11212', '13205', '11110'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.typrepa.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rentree  source  \n",
       "2017     inscri      1953678\n",
       "         culture       78298\n",
       "         enq26bis      26625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_all.head(5)\n",
    "df_all.value_counts(['rentree', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IntegerArray>\n",
       "[0, 1, <NA>]\n",
       "Length: 3, dtype: Int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.net.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compos</th>\n",
       "      <th>inspr</th>\n",
       "      <th>regime</th>\n",
       "      <th>annais</th>\n",
       "      <th>sexe</th>\n",
       "      <th>bac</th>\n",
       "      <th>anbac</th>\n",
       "      <th>situpre</th>\n",
       "      <th>conv</th>\n",
       "      <th>dipder</th>\n",
       "      <th>...</th>\n",
       "      <th>effectif</th>\n",
       "      <th>groupe</th>\n",
       "      <th>cursus_lmd</th>\n",
       "      <th>voie</th>\n",
       "      <th>flag_meef</th>\n",
       "      <th>etabli_diffusion</th>\n",
       "      <th>rentree</th>\n",
       "      <th>source</th>\n",
       "      <th>oppos</th>\n",
       "      <th>par_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0671864M</td>\n",
       "      <td>O</td>\n",
       "      <td>10</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2014</td>\n",
       "      <td>D</td>\n",
       "      <td>-1</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITE STRASBOURG</td>\n",
       "      <td>2017</td>\n",
       "      <td>inscri</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0671864M</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2014</td>\n",
       "      <td>D</td>\n",
       "      <td>-1</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITE STRASBOURG</td>\n",
       "      <td>2017</td>\n",
       "      <td>inscri</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0673021V</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2014</td>\n",
       "      <td>D</td>\n",
       "      <td>-1</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>X</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITE STRASBOURG</td>\n",
       "      <td>2017</td>\n",
       "      <td>inscri</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0671864M</td>\n",
       "      <td>O</td>\n",
       "      <td>10</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2015</td>\n",
       "      <td>D</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITE STRASBOURG</td>\n",
       "      <td>2017</td>\n",
       "      <td>inscri</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0671864M</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>2015</td>\n",
       "      <td>D</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNIVERSITE STRASBOURG</td>\n",
       "      <td>2017</td>\n",
       "      <td>inscri</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     compos inspr regime annais sexe bac anbac situpre conv dipder  ...  \\\n",
       "0  0671864M     O     10   1993    1   S  2014       D   -1      D  ...   \n",
       "1  0671864M     N     10   1993    1   S  2014       D   -1      D  ...   \n",
       "2  0673021V     N     10   1993    1   S  2014       D   -1      D  ...   \n",
       "3  0671864M     O     10   1997    1   S  2015       D   -1      A  ...   \n",
       "4  0671864M     N     10   1997    1   S  2015       D   -1      A  ...   \n",
       "\n",
       "  effectif groupe cursus_lmd voie flag_meef       etabli_diffusion rentree  \\\n",
       "0        1      4          L    0         0  UNIVERSITE STRASBOURG    2017   \n",
       "1        0      4          M   -1         0  UNIVERSITE STRASBOURG    2017   \n",
       "2        0      4          X   -1         0  UNIVERSITE STRASBOURG    2017   \n",
       "3        1      4          L    0         0  UNIVERSITE STRASBOURG    2017   \n",
       "4        0      4          M   -1         0  UNIVERSITE STRASBOURG    2017   \n",
       "\n",
       "   source oppos par_type  \n",
       "0  inscri    -1       -1  \n",
       "1  inscri    -1       -1  \n",
       "2  inscri    -1       -1  \n",
       "3  inscri    -1       -1  \n",
       "4  inscri    -1       -1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.info()\n",
    "df_all.head(5)\n",
    "# df.voie.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acabac',\n",
       " 'age',\n",
       " 'amena',\n",
       " 'anbac',\n",
       " 'annais',\n",
       " 'bac',\n",
       " 'bac_rgrp',\n",
       " 'bac_spe1',\n",
       " 'bac_spe2',\n",
       " 'cometa',\n",
       " 'comins',\n",
       " 'compos',\n",
       " 'conv',\n",
       " 'curpar',\n",
       " 'cursus_lmd',\n",
       " 'cycle',\n",
       " 'degetu',\n",
       " 'depbac',\n",
       " 'deprespa',\n",
       " 'dipder',\n",
       " 'diplom',\n",
       " 'echang',\n",
       " 'effectif',\n",
       " 'etabli',\n",
       " 'etabli_diffusion',\n",
       " 'exoins',\n",
       " 'flag_meef',\n",
       " 'flag_sup',\n",
       " 'groupe',\n",
       " 'inspr',\n",
       " 'nation',\n",
       " 'nature',\n",
       " 'nbach',\n",
       " 'net',\n",
       " 'niveau',\n",
       " 'niveau_d',\n",
       " 'niveau_f',\n",
       " 'numed',\n",
       " 'oppos',\n",
       " 'paripa',\n",
       " 'par_type',\n",
       " 'pcspar2',\n",
       " 'pcspar',\n",
       " 'regime',\n",
       " 'sectdis',\n",
       " 'sexe',\n",
       " 'situpre',\n",
       " 'specia',\n",
       " 'specib',\n",
       " 'specic',\n",
       " 'typ_dipl',\n",
       " 'typrepa',\n",
       " 'voie']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[conf.get('var_sise') for conf in CONF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier zip le plus récent est : C:/Users/zfriant/OneDrive/Inscrits/bcn/BCN_EXTRACT_530_5_20250720_083143.zip\n",
      "Liste des DataFrames :\n",
      "N_TYPE_DIPLOME_GENERIQUE_SISE\n",
      "N_TYPE_CLASSE_PREPA_SISE\n",
      "N_NIVEAU_SISE\n",
      "N_ORIGINE_RESSOURCE_SISE\n",
      "N_BCE_SISE_N\n",
      "N_DOMAINE_FORMATION_SISE\n",
      "N_ACADEMIE_ET_ASSIMILE\n",
      "N_PAYS_HISTO\n",
      "N_SESSION_EXAMEN\n",
      "N_VOIE_LMD\n",
      "N_REUSSITE_DIPLOME_SISE\n",
      "N_TYPE_DIPLOME_SISE\n",
      "N_CYCLE_SISE\n",
      "N_COMMUNE\n",
      "N_DIPLOME_ETAPE_SISE\n",
      "N_DUREE_ECHANGE_SISE\n",
      "N_AUTRE_CURSUS_SISE\n",
      "N_TYPE_ETABLISSEMENT_SISE\n",
      "N_FORMATIONS_SISE_HISTO\n",
      "N_GROUPE_DISCIPLINE_SISE\n",
      "N_SITUATION_ANNEE_PRECEDENTE\n",
      "N_DERNIER_DIPLOME_OBTENU\n",
      "N_SECTEUR_DISCIPL_DETAIL_SISE\n",
      "N_PROGRAMME_ECHANGE_INTERNATIO\n",
      "N_BAC\n",
      "N_CURSUS\n",
      "N_DIPLOME_SISE\n",
      "N_TYPE_HEBERGEMENT_SISE\n",
      "N_PRESENCE_EXAMEN\n",
      "N_AIDE_SISE\n",
      "N_PARCOURS_TYPE_SISE\n",
      "N_REUSSITE_EXAMEN_SISE\n",
      "N_REGIME_INSCRIPTION\n",
      "N_INSCRIPTION_PRINCIPALE\n",
      "N_PCS\n",
      "N_SEXE\n",
      "N_NATURE_DIPLOME_SISE\n",
      "N_ACTIVITE_PROFESSIONNELL_SISE\n",
      "N_ANNEE_DANS_FORMATION_SISE\n",
      "N_SPECIALISATION\n",
      "N_BAC_REGROUPE\n",
      "N_SECTEUR_DISCIPLINAIRE_SISE\n",
      "N_TELE_ENSEIGNEMENT\n",
      "N_PAYS\n",
      "N_TYPE_PARTIE_SISE\n",
      "N_NIVEAU_FORMATION\n",
      "N_TYPE_CLASSE_PREPA_RGPT_SISE\n",
      "N_TYPE_COMPOSANTE_SISE\n",
      "N_CONVENTION\n",
      "N_PROFIL_SISE\n",
      "N_SPECIALITE_BAC_2021_SISE\n",
      "N_GROUPE_ECOLE_MANAGEMENT_SISE\n",
      "N_DIPLOME_AUTRE_CURSUS_SISE\n",
      "N_BAC_REGROUPE_2\n",
      "N_DEPARTEMENT\n"
     ]
    }
   ],
   "source": [
    "from utils.vars_in_nomen import vbcn\n",
    "from utils.bcn_load import bcn_complete\n",
    "bcn=bcn_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_csv(pd.DataFrame(list(vbcn.items()), columns=['var_sise', 'n_data']), 'sise_config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIFS_dict = get_all_correctifs()\n",
    "BCN = bcn_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### acabac\n",
      "- le nom de variable acabac n'existe pas dans N_ACADEMIE_ET_ASSIMILE\n",
      " - le code suivant va extraire la 1ere colonne academie_et_assimile\n",
      "#### bac\n",
      "#### bac_rgrp\n",
      "- le nom de variable bac_rgrp n'existe pas dans N_BAC_REGROUPE_2\n",
      " - le code suivant va extraire la 1ere colonne bac_regroupe_2\n",
      "#### bac_spe1\n",
      "- le nom de variable bac_spe1 n'existe pas dans N_SPECIALITE_BAC_2021_SISE\n",
      " - le code suivant va extraire la 1ere colonne specialite_bac_2021_sise\n",
      "#### bac_spe2\n",
      "- le nom de variable bac_spe2 n'existe pas dans N_SPECIALITE_BAC_2021_SISE\n",
      " - le code suivant va extraire la 1ere colonne specialite_bac_2021_sise\n",
      "#### depbac\n",
      "- le nom de variable depbac n'existe pas dans N_DEPARTEMENT\n",
      " - le code suivant va extraire la 1ere colonne departement_insee_3\n",
      "#### inspr\n",
      "- le nom de variable inspr n'existe pas dans N_INSCRIPTION_PRINCIPALE\n",
      " - le code suivant va extraire la 1ere colonne inscription_principale\n",
      "#### cometa\n",
      "#### comins\n",
      "#### compos\n",
      "- le nom de variable compos n'existe pas dans N_BCE_SISE_N\n",
      " - le code suivant va extraire la 1ere colonne numero_uai\n",
      "#### etabli\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'PAYSAGE_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[38;5;66;03m# hors_nomen.to_csv(f\"{PATH}test/vars_hs_nomen.csv\", sep=';', encoding='utf-8', index=False, na_rep='', float_format='str')\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hors_nomen\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mvars_sise_to_be_check\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBCN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCORRECTIFS_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mvars_sise_to_be_check\u001b[39m\u001b[34m(year, bcn, com)\u001b[39m\n\u001b[32m     18\u001b[39m     l=pd.DataFrame.from_dict(com[nomen]).iloc[:,\u001b[32m0\u001b[39m].unique()\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m var_sise \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbcn\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnomen\u001b[49m\u001b[43m]\u001b[49m.columns:\n\u001b[32m     21\u001b[39m         l=bcn[nomen][var_sise].unique()\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'PAYSAGE_id'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def vars_sise_to_be_check(year, bcn, com):\n",
    "    from config_path import PATH\n",
    "    # from utils.vars_in_nomen import vbcn\n",
    "    import pandas as pd, json\n",
    "\n",
    "    CONF=json.load(open('utils/config_sise.json', 'r'))\n",
    "    vars_sise = pd.read_pickle(f\"{PATH}output/items_by_vars{year}.pkl\", compression='gzip')\n",
    "\n",
    "    hors_nomen=pd.DataFrame()\n",
    "\n",
    "    for conf in CONF:\n",
    "        var_sise = conf[\"var_sise\"]\n",
    "        nomen = conf[\"n_data\"]\n",
    "\n",
    "        if nomen:\n",
    "            print(f\"#### {var_sise}\")\n",
    "            if var_sise in ['cometa', 'comins']:\n",
    "                l=pd.DataFrame.from_dict(com[nomen]).iloc[:,0].unique()\n",
    "            else:\n",
    "                if var_sise in bcn[nomen].columns:\n",
    "                    l=bcn[nomen][var_sise].unique()\n",
    "                else:\n",
    "                    print(f\"- le nom de variable {var_sise} n'existe pas dans {nomen}\\n - le code suivant va extraire la 1ere colonne {bcn[nomen].columns[0]}\")\n",
    "                    l=bcn[nomen].iloc[:,0].unique()\n",
    "                \n",
    "            tmp=vars_sise.loc[(vars_sise.variable==var_sise)].assign(nomenclature=nomen)\n",
    "            tmp.loc[~tmp.item.isin(l), 'hors_nomenclature'] = '1'\n",
    "            hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)  \n",
    "\n",
    "        # hors_nomen.to_csv(f\"{PATH}test/vars_hs_nomen.csv\", sep=';', encoding='utf-8', index=False, na_rep='', float_format='str')\n",
    "   \n",
    "    return hors_nomen\n",
    "vars_sise_to_be_check(2024, BCN, CORRECTIFS_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hors_nomen=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    if k in bcn[v].columns:\n",
    "        l=bcn[v][k].unique()\n",
    "        # tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "        # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"- le nom de variable {k} n'existe pas dans {v}\\nla 1ere colonne est {bcn[v].iloc[:,0]}, le code suivant va extraire la 1ere colonne\")\n",
    "        l=bcn[v].iloc[:,0].unique()\n",
    "        tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))]\n",
    "        hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)      \n",
    "\n",
    "hors_nomen=hors_nomen.pivot_table(index=['rentree', 'variable', 'item'], columns='source',   values='count', \n",
    "    aggfunc='sum').reset_index()\n",
    "hors_nomen.fillna('',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# work_csv(hors_nomen, 'modalites_hsn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    l=bcn[v].iloc[:,0].unique()\n",
    "    tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "    # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=T:rue)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in vbcn.items():\n",
    "#     bcn[v].columns=bcn[v].columns.str.lower()\n",
    "#     l=bcn[v].iloc[:,0].unique()\n",
    "#     print(f\"{v} -> {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bcn:\n",
    "    x=bcn[i]\n",
    "    print(f\"{i} -> {x.iloc[:,0].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specialisation</th>\n",
       "      <th>libelle_1_specialisation</th>\n",
       "      <th>libelle_2_specialisation</th>\n",
       "      <th>date_ouverture</th>\n",
       "      <th>date_fermeture</th>\n",
       "      <th>date_intervention</th>\n",
       "      <th>gestion_diffusion</th>\n",
       "      <th>n_commentaire</th>\n",
       "      <th>variable_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [specialisation, libelle_1_specialisation, libelle_2_specialisation, date_ouverture, date_fermeture, date_intervention, gestion_diffusion, n_commentaire, variable_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcn['N_SPECIALISATION'][bcn['N_SPECIALISATION'].specialisation=='0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_csv(bcn['N_PARCOURS_TYPE_SISE'], 'parcours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.read_csv(f\"{PATH}sise_config.csv\", encoding='utf-8', na_values=' ', keep_default_na=False, sep=';', dtype='str')\n",
    "t.to_json('utils/config_sise.json', orient='records', compression='infer', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import sise_config\n",
    "CONF=sise_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'var_sise': 'acabac',\n",
       "  'n_data': 'N_ACADEMIE_ET_ASSIMILE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '99'},\n",
       " {'var_sise': 'age', 'n_data': '', 'format': 'str', 'missing_value': '-1'},\n",
       " {'var_sise': 'amena',\n",
       "  'n_data': 'N_AMENA',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'anbac', 'n_data': '', 'format': 'str', 'missing_value': ''},\n",
       " {'var_sise': 'annais', 'n_data': '', 'format': 'str', 'missing_value': '-1'},\n",
       " {'var_sise': 'bac', 'n_data': 'N_BAC', 'format': 'str', 'missing_value': ''},\n",
       " {'var_sise': 'bac_rgrp',\n",
       "  'n_data': 'N_BAC_REGROUPE_2',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'bac_spe1',\n",
       "  'n_data': 'N_SPECIALITE_BAC_2021_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'bac_spe2',\n",
       "  'n_data': 'N_SPECIALITE_BAC_2021_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'cometa',\n",
       "  'n_data': 'LES_COMMUNES',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'comins',\n",
       "  'n_data': 'LES_COMMUNES',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'compos',\n",
       "  'n_data': 'N_BCE_SISE_N',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'conv',\n",
       "  'n_data': 'N_CONVENTION',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'curpar',\n",
       "  'n_data': 'N_AUTRE_CURSUS_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'cursus_lmd',\n",
       "  'n_data': 'N_CURSUS',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'cycle',\n",
       "  'n_data': 'N_CYCLE_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'degetu',\n",
       "  'n_data': 'N_NIVEAU_FORMATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'depbac',\n",
       "  'n_data': 'N_DEPARTEMENT',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'deprespa',\n",
       "  'n_data': 'N_DEPARTEMENT',\n",
       "  'format': 'str',\n",
       "  'missing_value': '000'},\n",
       " {'var_sise': 'dipder',\n",
       "  'n_data': 'N_DERNIER_DIPLOME_OBTENU',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'diplom',\n",
       "  'n_data': 'N_DIPLOME_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'echang',\n",
       "  'n_data': 'N_PROGRAMME_ECHANGE_INTERNATIO',\n",
       "  'format': 'str',\n",
       "  'missing_value': '0'},\n",
       " {'var_sise': 'effectif', 'n_data': '', 'format': 'int', 'missing_value': ''},\n",
       " {'var_sise': 'etabli',\n",
       "  'n_data': 'PAYSAGE_id',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'etabli_diffusion',\n",
       "  'n_data': '',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'exoins',\n",
       "  'n_data': 'N_EXONERATIONS',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'flag_meef',\n",
       "  'n_data': 'N_MEEF',\n",
       "  'format': 'str',\n",
       "  'missing_value': '0'},\n",
       " {'var_sise': 'flag_sup',\n",
       "  'n_data': 'N_SUP',\n",
       "  'format': 'str',\n",
       "  'missing_value': '1'},\n",
       " {'var_sise': 'groupe',\n",
       "  'n_data': 'N_GROUPE_DISCIPLINE_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'inspr',\n",
       "  'n_data': 'N_INSCRIPTION_PRINCIPALE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'nation',\n",
       "  'n_data': 'N_PAYS',\n",
       "  'format': 'str',\n",
       "  'missing_value': '$'},\n",
       " {'var_sise': 'nature',\n",
       "  'n_data': 'N_NATURE_DIPLOME_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'nbach', 'n_data': '', 'format': 'int', 'missing_value': ''},\n",
       " {'var_sise': 'net', 'n_data': '', 'format': 'int', 'missing_value': ''},\n",
       " {'var_sise': 'niveau',\n",
       "  'n_data': 'N_ANNEE_DANS_FORMATION_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '00'},\n",
       " {'var_sise': 'niveau_d',\n",
       "  'n_data': 'N_NIVEAU_FORMATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'niveau_f',\n",
       "  'n_data': 'N_NIVEAU_FORMATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'numed', 'n_data': '', 'format': 'str', 'missing_value': ''},\n",
       " {'var_sise': 'oppos',\n",
       "  'n_data': 'N_OPPOSITION',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'paripa',\n",
       "  'n_data': 'N_PAYS',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'par_type',\n",
       "  'n_data': 'N_PARCOURS_TYPE_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'pcspar',\n",
       "  'n_data': 'N_PCS',\n",
       "  'format': 'str',\n",
       "  'missing_value': '99'},\n",
       " {'var_sise': 'regime',\n",
       "  'n_data': 'N_REGIME_INSCRIPTION',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'sectdis',\n",
       "  'n_data': 'N_SECTEUR_DISCIPLINAIRE_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-'},\n",
       " {'var_sise': 'sexe',\n",
       "  'n_data': 'N_SEXE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'situpre',\n",
       "  'n_data': 'N_SITUATION_ANNEE_PRECEDENTE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '9'},\n",
       " {'var_sise': 'specia',\n",
       "  'n_data': 'N_SPECIALISATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'specib',\n",
       "  'n_data': 'N_SPECIALISATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'specic',\n",
       "  'n_data': 'N_SPECIALISATION',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'typ_dipl',\n",
       "  'n_data': 'N_TYPE_DIPLOME_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'},\n",
       " {'var_sise': 'typrepa',\n",
       "  'n_data': 'N_TYPE_CLASSE_PREPA_SISE',\n",
       "  'format': 'str',\n",
       "  'missing_value': ''},\n",
       " {'var_sise': 'voie',\n",
       "  'n_data': 'N_VOIE_LMD',\n",
       "  'format': 'str',\n",
       "  'missing_value': '-1'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.load(open('utils/config_sise.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
