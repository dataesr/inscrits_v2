{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_path import PATH\n",
    "import warnings, json, pandas as pd, numpy as np \n",
    "from utils.functions_shared import reference_data_loader\n",
    "warnings.simplefilter(\"ignore\")\n",
    "global CORRECTIFS_dict, BCN, PAYSAGE_id\n",
    "CORRECTIFS_dict = reference_data_loader('google_sheet')\n",
    "BCN = reference_data_loader('bcn')\n",
    "PAYSAGE_id = reference_data_loader('paysage_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCN['N_BAC'].bac.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2024'\n",
    "CONF=json.load(open('utils/config_sise.json', 'r'))\n",
    "vars_sise = pd.read_pickle(f\"{PATH}output/items_by_vars2024.pkl\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_sise.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_sise.loc[vars_sise.variable=='etabli_diffusion'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etabli_paysage(year):\n",
    "    tmp=pd.read_pickle(f\"{PATH}output/frequency_etabli_source_year{year}.pkl\",compression= 'gzip')\n",
    "    print(f\"- size etabli {len(tmp)}\")\n",
    "\n",
    "    tmp=tmp.merge(pd.DataFrame(PAYSAGE_id)[['id_value','id_paysage', 'usualname', 'active','id_enddate']], how='left', left_on='etabli', right_on='id_value').drop_duplicates()\n",
    "\n",
    "    tmp=tmp.assign(paysage_presence=np.where(tmp.id_value.isnull(), 'N', 'Y'))\n",
    "    tmp.loc[~tmp.id_enddate.isnull(), 'end_year'] = tmp.loc[~tmp.id_enddate.isnull()].id_enddate.str.split('-').str[0]\n",
    "    tmp['pid_multi']=tmp.groupby(['rentree', 'source', 'etabli', 'compos']).transform('size')\n",
    "\n",
    "    print(f\"- size etabli+paysage {len(tmp)}\")\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hors_nomen=pd.DataFrame()\n",
    "\n",
    "for conf in CONF:\n",
    "    var_sise = conf[\"var_sise\"]\n",
    "    nomen = conf[\"n_data\"]\n",
    "\n",
    "    if nomen:\n",
    "        if var_sise in ['cometa', 'comins']:\n",
    "            # l=pd.DataFrame.from_dict(CORRECTIFS_dict[nomen]).iloc[:,0].unique()\n",
    "            l=pd.DataFrame.from_dict(CORRECTIFS_dict['LES_COMMUNES'])[['COM_CODE', 'COM_NOM']]\n",
    "        elif var_sise in ['etabli']:\n",
    "            etabli=etabli_paysage(year)\n",
    "        else:\n",
    "            if var_sise in BCN[nomen].columns:\n",
    "                l=BCN[nomen][[var_sise, 'libelle_long']]\n",
    "            else:\n",
    "                print(f\"*> {var_sise} n'existe pas dans {nomen}\\n  - le code suivant va extraire la 1ere colonne {BCN[nomen].columns[0]}\")\n",
    "                l=BCN[nomen].iloc[:,0].unique()\n",
    "\n",
    "        tmp=vars_sise.loc[(vars_sise.variable==var_sise)].assign(nomenclature=nomen)\n",
    "        tmp=tmp.assign(hors_nomenclature=np.where(~tmp.item.isin(l.iloc[:,0].unique()), '1', '0'))\n",
    "        # tmp.loc[~tmp.item.isin(l), 'hors_nomenclature'] = '1'\n",
    "        hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hors_nomen=pd.DataFrame()\n",
    "for conf in CONF:\n",
    "    if conf['var_sise'] not in ['etabli', 'compos']:\n",
    "        var_sise = conf[\"var_sise\"]\n",
    "        nomen = conf[\"n_data\"]\n",
    "\n",
    "        if nomen:\n",
    "            if var_sise in ['cometa', 'comins']:\n",
    "                # l=pd.DataFrame.from_dict(CORRECTIFS_dict[nomen]).iloc[:,0].unique()\n",
    "                l=(pd.DataFrame.from_dict(CORRECTIFS_dict['LES_COMMUNES'])[\n",
    "                                            ['COM_CODE', 'COM_NOM']]\n",
    "                                            .rename(columns={'COM_CODE':'item', 'COM_NOM':'libelle'}))\n",
    "            else:\n",
    "                if var_sise in BCN[nomen].columns:\n",
    "                    if 'libelle_long' in BCN[nomen].columns:\n",
    "                        l=BCN[nomen][[var_sise, 'libelle_long']].rename(columns={var_sise:'item', 'libelle_long':'libelle'})\n",
    "                    else:\n",
    "                        print(f\"- trouver le libelle pour {var_sise}\\n{BCN[nomen].columns}\")\n",
    "                else:\n",
    "                    # print(f\"*> {var_sise} n'existe pas dans {nomen}\\n  - le code suivant va extraire la 1ere colonne {BCN[nomen].columns[0]}\")\n",
    "                    if 'libelle_long' in BCN[nomen].columns:\n",
    "                        l=BCN[nomen][[BCN[nomen].columns[0], 'libelle_long']].rename(columns={BCN[nomen].columns[0]:'item', 'libelle_long':'libelle'})\n",
    "                    else:\n",
    "                        libelle_columns = [col for col in BCN[nomen].columns if col.startswith('libelle')]\n",
    "                        l=BCN[nomen][[BCN[nomen].columns[0], libelle_columns[0]]].rename(columns={BCN[nomen].columns[0]:'item', libelle_columns[0]:'libelle'})\n",
    "                        \n",
    "            tmp=vars_sise.loc[(vars_sise.variable==var_sise)].assign(nomenclature=nomen)\n",
    "            tmp=tmp.assign(hors_nomenclature=np.where(~tmp.item.isin(l.item.unique()), '1', '0'))\n",
    "            tmp=tmp.merge(l, how='left', on='item')\n",
    "            hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hors_nomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=BCN['N_DIPLOME_SISE']\n",
    "y.loc[(y.libelle_intitule_1.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_source(source, rentree):\n",
    "    import pandas as pd, zipfile\n",
    "    from modules.sise_content import src_load\n",
    "\n",
    "    filename = f'{source}{str(rentree)[2:4]}'\n",
    "    print(filename)\n",
    "\n",
    "    from config_path import PATH\n",
    "    with zipfile.ZipFile(f\"{PATH}input/parquet_origine.zip\", 'r') as z:\n",
    "        df = pd.read_parquet(z.open(f'{filename}.parquet'), engine='pyarrow')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=get_individual_source('mana', '2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TYPREPA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global CONF\n",
    "CONF=json.load(open('utils/config_sise.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_RENTREES = list(range(2004, 2004+1))\n",
    "ALL_RENTREES = [2013]\n",
    "for rentree in ALL_RENTREES:\n",
    "    df_all = pd.DataFrame()\n",
    "    # sources = get_sources(rentree)\n",
    "    sources = ['mana']\n",
    "    for source in sources:\n",
    "\n",
    "        filename = f'{source}{str(rentree)[2:4]}'\n",
    "        print(filename)\n",
    "\n",
    "\n",
    "        # chargement des tables en conservant que les variables de la liste utils/vars_list\n",
    "        df = src_load(filename, source, rentree)\n",
    "\n",
    "        # to check the data from the new datasets\n",
    "        # with pd.ExcelWriter(excel_path, mode='a', if_sheet_exists=\"replace\") as writer:  \n",
    "        #     pd.DataFrame({\"name\": df.columns, \"non-nulls\": len(df)-df.isnull().sum().values, \"nulls\": df.isnull().sum().values}).to_excel(writer, sheet_name=filename, index=False)\n",
    "\n",
    "        # df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "    # df_all = correctif_vars(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.typrepa.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.head(5)\n",
    "df_all.value_counts(['rentree', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.net.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "df_all.head(5)\n",
    "# df.voie.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[conf.get('var_sise') for conf in CONF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRECTIFS_dict = get_all_correctifs()\n",
    "BCN = bcn_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vars_sise_to_be_check(year, bcn, com):\n",
    "    from config_path import PATH\n",
    "    # from utils.vars_in_nomen import vbcn\n",
    "    import pandas as pd, json\n",
    "\n",
    "    CONF=json.load(open('utils/config_sise.json', 'r'))\n",
    "    vars_sise = pd.read_pickle(f\"{PATH}output/items_by_vars{year}.pkl\", compression='gzip')\n",
    "\n",
    "    hors_nomen=pd.DataFrame()\n",
    "\n",
    "    for conf in CONF:\n",
    "        var_sise = conf[\"var_sise\"]\n",
    "        nomen = conf[\"n_data\"]\n",
    "\n",
    "        if nomen:\n",
    "            print(f\"#### {var_sise}\")\n",
    "            if var_sise in ['cometa', 'comins']:\n",
    "                l=pd.DataFrame.from_dict(com[nomen]).iloc[:,0].unique()\n",
    "            else:\n",
    "                if var_sise in bcn[nomen].columns:\n",
    "                    l=bcn[nomen][var_sise].unique()\n",
    "                else:\n",
    "                    print(f\"- le nom de variable {var_sise} n'existe pas dans {nomen}\\n - le code suivant va extraire la 1ere colonne {bcn[nomen].columns[0]}\")\n",
    "                    l=bcn[nomen].iloc[:,0].unique()\n",
    "                \n",
    "            tmp=vars_sise.loc[(vars_sise.variable==var_sise)].assign(nomenclature=nomen)\n",
    "            tmp.loc[~tmp.item.isin(l), 'hors_nomenclature'] = '1'\n",
    "            hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)  \n",
    "\n",
    "        # hors_nomen.to_csv(f\"{PATH}test/vars_hs_nomen.csv\", sep=';', encoding='utf-8', index=False, na_rep='', float_format='str')\n",
    "   \n",
    "    return hors_nomen\n",
    "vars_sise_to_be_check(2024, BCN, CORRECTIFS_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hors_nomen=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    if k in bcn[v].columns:\n",
    "        l=bcn[v][k].unique()\n",
    "        # tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "        # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"- le nom de variable {k} n'existe pas dans {v}\\nla 1ere colonne est {bcn[v].iloc[:,0]}, le code suivant va extraire la 1ere colonne\")\n",
    "        l=bcn[v].iloc[:,0].unique()\n",
    "        tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))]\n",
    "        hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=True)      \n",
    "\n",
    "hors_nomen=hors_nomen.pivot_table(index=['rentree', 'variable', 'item'], columns='source',   values='count', \n",
    "    aggfunc='sum').reset_index()\n",
    "hors_nomen.fillna('',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# work_csv(hors_nomen, 'modalites_hsn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=pd.DataFrame()\n",
    "for k,v in vbcn.items():\n",
    "    bcn[v].columns=bcn[v].columns.str.lower()\n",
    "    l=bcn[v].iloc[:,0].unique()\n",
    "    tmp=vars_sise.loc[(vars_sise.variable==k)&(~vars_sise.item.isin(l))].value_counts(vs_cols_base, dropna=False).reset_index()\n",
    "    # hors_nomen=pd.concat([hors_nomen, tmp], ignore_index=T:rue)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in vbcn.items():\n",
    "#     bcn[v].columns=bcn[v].columns.str.lower()\n",
    "#     l=bcn[v].iloc[:,0].unique()\n",
    "#     print(f\"{v} -> {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bcn:\n",
    "    x=bcn[i]\n",
    "    print(f\"{i} -> {x.iloc[:,0].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcn['N_SPECIALISATION'][bcn['N_SPECIALISATION'].specialisation=='0000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_csv(bcn['N_PARCOURS_TYPE_SISE'], 'parcours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.read_csv(f\"{PATH}sise_config.csv\", encoding='utf-8', na_values=' ', keep_default_na=False, sep=';', dtype='str')\n",
    "t.to_json('utils/config_sise.json', orient='records', compression='infer', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import sise_config\n",
    "CONF=sise_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.load(open('utils/config_sise.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
